# Default experiment configuration for RLOO fine-tuning on a small code dataset
# Adjust paths and hyperparameters to fit your Kaggle environment constraints.

run:
  output_dir: /kaggle/working/rloo_runs/default
  logging_steps: 5
  save_steps: 50
  eval_strategy: steps
  eval_steps: 50
  max_steps: 200
  gradient_accumulation_steps: 2
  mixed_precision: bf16 # switch to "fp16" if bf16 is unavailable

model:
  name_or_path: Salesforce/codegen-350M-mono
  revision: main
  trust_remote_code: false
  use_peft_lora: true
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05

reward:
  shaping: heuristic # options: heuristic | lexical_overlap (extend in prompts.py)
  baseline: running_mean
  clip_range: 5.0

optimizer:
  learning_rate: 5.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01

prompt:
  max_source_length: 256
  max_new_tokens: 128
  stop_sequences:
    - "\n\n"

dataset:
  name: codeparrot/codeparrot-clean
  split: train
  streaming: true
  sample_size: 1000
  language_filter: python

inference:
  num_return_sequences: 4
  temperature: 0.7
  top_p: 0.95

seed: 42
